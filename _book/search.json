[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "um5mee12",
    "section": "",
    "text": "À propos\nCe site héberge le matériel du cours de mesures pour la mécanique des fluides par PIV de l’unité d’enseignement UM5MEE12 - Méthodes expérimentales et traitement des données donnée au sein du master sciences de l’ingénieur à l’UFR d’Ingénierie de Sorbonne Université. L’objectif est d’appréhender les concepts de base inhérents à la mesure du champ de vitesse en écoulement de fluides.\n\n\n\n\n\n\nNote\n\n\n\nCe cours est en partie adapté de la documentation d’OpenPIV, sous licence GNU General Public License v2.0.\n\n\nLe contenu du cours se divise en deux parties :\n\nLes aspects théoriques du cours, notamment :\n\nles considérations physiques fondamentales liées aux particules traceurs de l’écoulement à mesurer\nl’algorithmique imaginée afin d’avoir accès au champ de vecteur vitesse à partir de l’analyse d’images de particules\n\nLes aspects pratiques :\n\nune partie numérique pour davantage s’approprier les méthodes d’évaluation par PIV. Les images traitées seront générées synthétiquement\nune partie expérimentale afin d’appréhender les compromis à atteindre afin d’obtenir des images de qualité à traiter\n\n\nDans ce cours, on utilisera principalement les outils suivants, avec lesquels les étudiants et étudiantes doivent être familiers :\n\nPython\nNumpy\nMatplotlib\n\n\n\nÉvaluation\nL’évaluation se fera sur la base d’un petit compte rendu de tp (pour la partie numérique) et d’un rapport de projet portant sur l’exploitation des données expérimentales obtenues lors des séances de tp.\n\n\nCalendrier\nVoici l’organisation prévisionnelle des séances :\n\n\n\n\n\n\n\n\nSemaine\nDate\nThème\n\n\n\n\n1\n24/09/2025\nIntroduction à la mesure du champ de vitesse par PIV, CM 1\n\n\n2\n01/10/2025\nAlgorithmique et spécificités expérimentales, TP 1 + TP 2\n\n\n3\n08/10/2025\nAlgorithmique et spécificités expérimentales, TP 1 + TP 2\n\n\n\n\n\nLectures et média recommandés\nVous trouverez ci-dessous trouverez une liste de ressources utiles à votre projet, par thème\n\nPython pour la programmation scientifique\n\nUn Zeste de Python\nLes bases de numpy et matplotlib\nFrom Python to Numpy\nScientific Visualization: Python + Matplotlib (N. P. Rougier 2021)\n\n\n\nProductions scientifiques : figures et rapports\n\nTen Simple Rules for Better Figures (M. D. Rougier Nicolas P. 2014)\nWikibook LaTeX\nTypst\n\n\n\n\n\nRougier, Michael Droettboom, Nicolas P. 2014. “Ten Simple Rules for Better Figures.” PLOS Computational Biology 10 (9). https://doi.org/10.1371/journal.pcbi.1003833.\n\n\nRougier, Nicolas P. 2021. Scientific Visualization: Python + Matplotlib. CRC Press.",
    "crumbs": [
      "À propos"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Rougier, Michael Droettboom, Nicolas P. 2014. “Ten Simple Rules\nfor Better Figures.” PLOS Computational Biology 10 (9).\nhttps://doi.org/10.1371/journal.pcbi.1003833.\n\n\nRougier, Nicolas P. 2021. Scientific Visualization: Python +\nMatplotlib. CRC Press.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "piv_basics.html",
    "href": "piv_basics.html",
    "title": "1  Basics of PIV",
    "section": "",
    "text": "1.1 What is Particle Image Velocimetry (PIV) about?\nUsing simple mathematical knowledge and existing algorithms written with Python, Numpy, Scipy, we will introduce the basics of PIV.\n“Particle” Image Velocimetry (PIV) is a non-intrusive state-of-the-art technique1,2 to get the velocity field of the flow being studied from images of small particles, called tracers.\nIt is based on image recording of the illuminated flow field using seeding particles (called tracers) which, when sufficiently small compared to the smallest characteristic length scales of the flow, are assumed to faithfully follow the flow dynamics (the degree to which the particles faithfully follow the flow is represented by the Stokes number). In practice, common sizes of the tracer particles are in the order of 5-100 microns. The entrained particles are generally made visible in a cross-section of the flow being studied by forming a coherent light sheet. In practice, the flow is illuminated twice using a laser light sheet, forming a plane where a camera is focused. The time delay between the pulses depends on the mean velocity and the image magnification. It is assumed that the tracer particles follow the local flow velocity between the two consecutive illuminations. The light scattered from the tracer particles is then imaged via an optical lens on a digital camera. The displacement of the particle images between two consecutive light pulses (respectively, frames) is determined through evaluation of the spatial cross-correlation function and image processing tools as implemented in OpenPIV.\nThe effectiveness of the measurement results strongly depends on a large number of parameters such as particles concentration, size distribution and shape, illumination source, recording device, and synchronization between the illumination, acquisition and recording systems (Huang et al., 1997). An appropriate choice of the different parameters of the cross correlation analysis (e.g., interrogation area, time between pulses, scaling) will influence the results accuracy.\nRead more about PIV in the following chapters:\n1 Raffel et al., 2007\n2 Adrian, 1991",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of PIV</span>"
    ]
  },
  {
    "objectID": "piv_basics.html#how-to-estimate-a-velocity-field-from-a-couple-of-grayscale-particle-images",
    "href": "piv_basics.html#how-to-estimate-a-velocity-field-from-a-couple-of-grayscale-particle-images",
    "title": "1  Basics of PIV",
    "section": "1.2 How to estimate a velocity-field from a couple of grayscale particle images?",
    "text": "1.2 How to estimate a velocity-field from a couple of grayscale particle images?\nThis tutorial will follow the simplest analysis path from the two images to the velocity field and some post-analysis.\n\n# import the standard numerical and plotting packages\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# import what is necessary from OpenPIV\nfrom openpiv import tools, pyprocess, validation, filters, scaling\n\nWe have downloaded some sample images from a standard PIV images project, see http://www.pivchallenge.org/pub/#b\n\n# load the images\na = tools.imread(\"./images/B005_1.tif\")\nb = tools.imread(\"./images/B005_2.tif\")\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 4))\n\nimg = axs[0].imshow(a, vmin=0, vmax=100, cmap=plt.cm.gray)\naxs[0].set_title('frame A')\n\nimg = axs[1].imshow(b, vmin=0, vmax=100, cmap=plt.cm.gray)\naxs[1].set_title('frame B')\n\ncbar = fig.add_axes([0.95, 0.1, 0.03, 0.8])\nfig.colorbar(img, cax=cbar)\nplt.show()\n\n\n\n\n\n\n\n\nThe two images show the particles at two different times. But these images are way to big and contain too many particles to manually track the movement of individual particles from one frame to the other. Instead, we can analyze small regions of interest, called interrogation windows (IW). Typically, we can start with a size of 32 x 32 pixels or smaller. Until recently, the fast algorithms used powers of 2, so the historical sizes are always powers of 2: 8, 16, 32, 64, 128, …\nLet’s take the first top left windows from each image.\n\nwin_size = 32\n\na_win = a[:win_size, :win_size].copy()\nb_win = b[:win_size, :win_size].copy()\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 4))\nimg = axs[0].imshow(a_win, vmin=0, vmax=100, cmap=plt.cm.gray)\naxs[0].set_title('IA')\n\nimg = axs[1].imshow(b_win, vmin=0, vmax=100, cmap=plt.cm.gray)\naxs[1].set_title('IB')\n\ncbar = fig.add_axes([0.95, 0.1, 0.03, 0.8])\nfig.colorbar(img, cax=cbar)\nplt.show()\n\n\n\n\n\n\n\n\nIf you tried to manually track the movement of individual particles from frame A to frame B, it would be extremely time-consuming, especially for large image regions containing many particles. Manually identifying and matching every single particle would quickly become tedious and impractical for even a coarse velocity field estimation. That’s why automated methods, such as using correlation techniques or least squares approaches, are preferred in Particle Image Velocimetry (PIV). These methods can efficiently analyze the displacement of all particles within interrogation windows and generate a velocity field much faster and more accurately than manual matching.\nWe can find out the distance that all the particles moved between frame A and frame B using the principles of least squares or correlations, but let’s first try to get it manually.\nIf we try to shift the window IA by some pixels along the horizontal and/or vertical directions, we shall see an image that gets closer in resemblance to the window IB.\nAssignment: Modify the code below to minimize the difference between the shifted IA and IB.\n\nfig, axs = plt.subplots(1, 3, figsize=(9, 4))\n\nimg = axs[0].imshow(a_win, cmap=plt.cm.gray)\naxs[0].set_title(\"IA(shift=0)\")\n\nimg = axs[1].imshow(np.roll(a_win, (0, 1), axis=(0, 1)), cmap=plt.cm.gray)\naxs[1].set_title(\"IA(shift=1 pxl)\")\n\nimg = axs[2].imshow(b_win, cmap=plt.cm.gray)\naxs[2].set_title(\"IB\")\n\ncbar = fig.add_axes([0.95, 0.1, 0.03, 0.8])\nfig.colorbar(img, cax=cbar)\nplt.show()\n\n\n\n\n\n\n\n\nIf we now subtract from IB the shifted IA, we shall see how good the shift predicts the real displacement between the two.\nAssignment: Modify the code below to minimize the difference between the shifted IA and IB. Share your comments.\n\nfig, axs = plt.subplots(1, 3, figsize=(9, 4))\n\nimg = axs[0].imshow(b_win - a_win, cmap=plt.cm.gray)\naxs[0].set_title(\"IB - IA(shift=0)\")\n\nimg = axs[1].imshow(b_win - np.roll(a_win, (1, 0), axis=(0, 1)), cmap=plt.cm.gray)\naxs[1].set_title(\"IB - IA(shift=1 pxl)\")\n\nimg = axs[2].imshow(b_win - np.roll(a_win, (2, 0), axis=(0, 1)), cmap=plt.cm.gray)\naxs[2].set_title(\"IB - IA(shift=2 pxl)\")\n\ncbar = fig.add_axes([0.95, 0.1, 0.03, 0.8])\nfig.colorbar(img, cax=cbar)\nplt.show()\n\n\n\n\n\n\n\n\nLet’s try to find the best shift algorithmically: shift and calculate the sum of squared differences, the minimum of which should be the best shift.\n\ndef match_template(img, template, maxroll=8):\n    # img: input image to compare\n    # template: image to match against\n    # maxroll: max nbr of pxl to shift in each dir. Default value is 8.\n    best_dist = np.inf\n    best_shift = (-1, -1)\n    for y in range(-maxroll,maxroll):\n        for x in range(-maxroll,maxroll):\n            # calculate Euclidean distance\n            dist = np.sqrt(np.sum((img - np.roll(template, (y, x), axis=(0, 1))) ** 2))\n            if dist &lt; best_dist:\n                best_dist = dist\n                best_shift = (y, x)\n    return (best_dist, best_shift)\n\nLet’s check that it works by manually shifting the same image (IA):\n\nmatch_template(np.roll(a_win, (2, 0), axis=(0, 1)), a_win)\n\n(0.0, (2, 0))\n\n\nIndeed, when we find the correct shift, we get zero distance. It’s not so in real images:\n\nmatch_template(b_win, a_win)\n\n(123.80226169178009, (-1, 1))\n\n\nWell, this is not the true displacement, but it gives a hint.\nWe could draw this as a vector of velocity\n\\[\n    u = \\frac{\\Delta x \\text{ pixels}}{\\Delta t} ,\\qquad v = \\frac{\\Delta y \\text{ pixels}}{\\Delta t}\n\\]\nwhere \\(\\Delta t\\) is the time interval (delay) between the two images (or two laser pulses).\nThe problem is that shifting each image and repeating the loop many times is impractical.\nHowever, one can get it by using a different matching principle, based on the property called cross-correlation (cross because we use two different images). This is an efficient computational algorithm to find out the right shift. You can see more details here: http://paulbourke.net/miscellaneous/correlate/.\n\nfrom scipy.signal import correlate\n\ncross_corr = correlate(b_win - b_win.mean(), a_win - a_win.mean(), method=\"fft\")\n# Note that it's approximately twice as large as the original windows, as we\n# can shift a_win by a maximum of its size horizontally and vertically\n# while still maintaining some overlap between the two windows.\nprint(\"Size of the correlation map: %d x %d\" % cross_corr.shape)\n\nSize of the correlation map: 63 x 63\n\n\n\n# let's see what the cross-correlation looks like\n#from mpl_toolkits.mplot3d import Axes3D\nY, X = np.meshgrid(np.arange(cross_corr.shape[0]), np.arange(cross_corr.shape[1]))\n\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.plot_surface(Y, X, cross_corr, cmap='jet', linewidth=0.2)  # type: ignore\nplt.title(\"Correlation map — peak is the most probable shift\")\nplt.show()\n\n# let's see the same correlation map, from above\nplt.imshow(cross_corr, cmap=plt.cm.gray)\ny, x = np.unravel_index(cross_corr.argmax(), cross_corr.shape)\nprint(f\"{y=}, {x=}\")\nplt.plot(x, y, \"ro\")\nplt.show()\n\n\n\n\n\n\n\n\ny=30, x=32\n\n\n\n\n\n\n\n\n\nThe image of the correlation map shows the same result that we got manually looping. We need to substract the center of symmetry (31, 31) to get the estimated displacement.\n\ndy, dx = y - 31, x - 31\nprint(f\"{dy=}, {dx=}\")\n\ndy=-1, dx=1\n\n\nWe can get the first velocity field by repeating this analysis for all small windows. Let’s take 32 x 32 pixels windows from each image and do the loop:\n\ndef vel_field(curr_frame, next_frame, win_size):\n    ys = np.arange(0, curr_frame.shape[0], win_size)\n    xs = np.arange(0, curr_frame.shape[1], win_size)\n    dys = np.zeros((len(ys), len(xs)))\n    dxs = np.zeros((len(ys), len(xs)))\n    for iy, y in enumerate(ys):\n        for ix, x in enumerate(xs):\n            int_win = curr_frame[y : y + win_size, x : x + win_size]\n            search_win = next_frame[y : y + win_size, x : x + win_size]\n            cross_corr = correlate(\n                search_win - search_win.mean(), int_win - int_win.mean(), method=\"fft\"\n            )\n            dys[iy, ix], dxs[iy, ix] = (\n                np.unravel_index(np.argmax(cross_corr), cross_corr.shape)\n                - np.array([win_size, win_size])\n                + 1\n            )\n    # draw velocity vectors from the center of each window\n    ys = ys + win_size / 2\n    xs = xs + win_size / 2\n    return xs, ys, dxs, dys\n\n\nxs, ys, dxs, dys = vel_field(a, b, 32)\nnorm_drs = np.sqrt(dxs ** 2 + dys ** 2)\n\nfig, ax = plt.subplots(figsize=(9, 4))\n# we need these flips on y since quiver uses a bottom-left origin, while our\n# arrays use a top-right origin\nax.quiver(\n    xs,\n    ys[::-1],\n    dxs,\n    -dys,\n    norm_drs,\n    cmap=\"plasma\",\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=0.25,\n)\nax.set_aspect(\"equal\")\nplt.show()\n\n\n\n\n\n\n\n\nIf you’ve followed along this far, great! Now you understand the basics.\nWe can also try out a variant of this that uses a search window larger than the interrogation window instead of relying on zero-padding. By avoiding using zero-padding around the search window, movement detection should theoretically be a bit better, assuming that the window sizes are chosen well.\n\ndef vel_field_asymmetric_wins(\n    curr_frame, next_frame, half_int_win_size, half_search_win_size\n):\n    ys = np.arange(half_int_win_size[0], curr_frame.shape[0], 2 * half_int_win_size[0])\n    xs = np.arange(half_int_win_size[1], curr_frame.shape[1], 2 * half_int_win_size[1])\n    dys = np.zeros((len(ys), len(xs)))\n    dxs = np.zeros((len(ys), len(xs)))\n    for iy, y in enumerate(ys):\n        for ix, x in enumerate(xs):\n            int_win = curr_frame[\n                y - half_int_win_size[0] : y + half_int_win_size[0],\n                x - half_int_win_size[1] : x + half_int_win_size[1],\n            ]\n            search_win_y_min = y - half_search_win_size[0]\n            search_win_y_max = y + half_search_win_size[0]\n            search_win_x_min = x - half_search_win_size[1]\n            search_win_x_max = x + half_search_win_size[1]\n            truncated_search_win = next_frame[\n                max(0, search_win_y_min) : min(b.shape[0], search_win_y_max),\n                max(0, search_win_x_min) : min(b.shape[1], search_win_x_max),\n            ]\n            cross_corr = correlate(\n                truncated_search_win - np.mean(truncated_search_win),\n                int_win - np.mean(int_win),\n                mode=\"valid\",\n                method=\"fft\",\n            )\n            dy, dx = np.unravel_index(np.argmax(cross_corr), cross_corr.shape)\n            # if the top of the search window got truncated, shift the origin\n            # up to the top edge of the (non-truncated) search window\n            if search_win_y_min &lt; 0:\n                dy += -search_win_y_min\n            # if the left of the search window got truncated, shift the origin\n            # over to the left edge of the (non-truncated) search window\n            if search_win_x_min &lt; 0:\n                dx += -search_win_x_min\n            # shift origin to the center of the search window\n            dy -= half_search_win_size[0] - half_int_win_size[0]\n            dx -= half_search_win_size[1] - half_int_win_size[1]\n            dys[iy, ix] = dy\n            dxs[iy, ix] = dx\n    return xs, ys, dxs, dys\n\n\nint_win_size = np.array([32, 32])\nprint(f\"{int_win_size=}\")\nassert np.all(np.array(a.shape) % int_win_size == 0)\nassert np.all(int_win_size % 2 == 0)\nhalf_int_win_size = int_win_size // 2\n\nsearch_win_size = int_win_size * 2\nprint(f\"{search_win_size=}\")\nassert np.all(search_win_size % 2 == 0)\nhalf_search_win_size = search_win_size // 2\nassert np.all(search_win_size &gt; int_win_size)\nprint(\n    \"max velocity that can be detected with these window sizes: \"\n    + f\"{half_search_win_size - half_int_win_size}\"\n)\n\nint_win_size=array([32, 32])\nsearch_win_size=array([64, 64])\nmax velocity that can be detected with these window sizes: [16 16]\n\n\nMaking the search window larger compared to the interrogation window would allow for larger velocities to be detected.\n\nxs_asym, ys_asym, dxs_asym, dys_asym = vel_field_asymmetric_wins(\n    a, b, half_int_win_size, half_search_win_size\n)\nnorm_drs_asym = np.sqrt(dxs_asym ** 2 + dys_asym ** 2)\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 4))\naxs[0].quiver(\n    xs,\n    ys[::-1],\n    dxs,\n    -dys,\n    norm_drs,\n    cmap=\"plasma\",\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=0.25,\n)\naxs[1].quiver(\n    xs_asym,\n    ys_asym[::-1],\n    dxs_asym,\n    -dys_asym,\n    norm_drs_asym,\n    cmap=\"plasma\",\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=0.25,\n)\naxs[0].set_title(\n    f\"{win_size} x {win_size} int. win. + \"\n    f\"{win_size} x {win_size} 0-padded search win.\"\n)\naxs[1].set_title(\n    f\"{int_win_size[0]} x {int_win_size[1]} int. win. + \"\n    f\"{search_win_size[0]} x {search_win_size[0]} unpadded search win.\"\n)\nax.set_aspect(\"equal\")\nplt.show()",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of PIV</span>"
    ]
  },
  {
    "objectID": "piv_basics.html#additional-examples",
    "href": "piv_basics.html#additional-examples",
    "title": "2  Basics of PIV",
    "section": "2.3 Additional examples",
    "text": "2.3 Additional examples\n\n2.3.1 Run this Jupyter notebook without installation:\nNow you can take our online Jupyter notebook and process any pairs of images yourself, on the cloud, http://github.com/openpiv/openpiv-python-example.\nDownload the OpenPIV and try it yourself: https://github.com/OpenPIV\n\n\n2.3.2 See multiple examples\nIncluding how to work with movies, different series of files, all kind of tips and tricks in our repository of Jupyter notebooks in the https://github.com/OpenPIV/openpiv-python-examples",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of PIV</span>"
    ]
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "2  OpenPIV first tutorial",
    "section": "",
    "text": "2.1 Processing\nUsing open source software, OpenPIV (http://www.openpiv.net), written with Python, Numpy, Scipy (http://www.scipy.org), we will introduce the basics of PIV.\nThis tutorial will follow the simplest analysis path from the two images to the velocity field and some post-analysis.\nWe are going to use the extended_search_area_piv function, wich is a standard PIV cross-correlation algorithm.\nThis function allows the search area (search_area_size) in the second frame to be larger than the interrogation window in the first frame (window_size). Also, the search areas can overlap (overlap).\nThe extended_search_area_piv function will return three arrays: 1. The u component of the velocity field 2. The v component of the velocity field 3. The signal-to-noise ratio (sig2noise) of the cross-correlation map of each vector. The higher the signal-to-noise ratio, the higher the probability that its magnitude and direction are correct.\n# define the PIV analysis parameters\nwinsize = 24 # size of the interrogation window in frame A, in pixels\nsearchsize = 32  # size of the window in frame B (searchsize is larger or equal to winsize), in pixels\noverlap = 12 # overlap between the neighbouring windows, in pixels\ndt = 0.02 # time interval of the PIV recording, in sec\nu, v, sig2noise = pyprocess.extended_search_area_piv(\n    frame_a.astype(np.int32),\n    frame_b.astype(np.int32),\n    window_size=winsize,\n    overlap=overlap,\n    dt=dt,\n    search_area_size=searchsize,\n    sig2noise_method='peak2peak',\n)\nThe function get_coordinates finds the center of each interrogation window. This will be useful later on when plotting the vector field.\n# get a list of coordinates for the vector field\nx, y = pyprocess.get_coordinates(\n    image_size=frame_a.shape,\n    search_area_size=searchsize,\n    overlap=overlap,\n)",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>OpenPIV first tutorial</span>"
    ]
  },
  {
    "objectID": "tutorial.html#post-processing",
    "href": "tutorial.html#post-processing",
    "title": "2  OpenPIV first tutorial",
    "section": "2.2 Post-processing",
    "text": "2.2 Post-processing\nStrictly speaking, we are ready to plot the vector field. However, some spurious vectors might locally impact the quality of the results. It might therefore be useful to apply some filtering.\nTo start, let’s use the function sig2noise_val to get a mask indicating which vectors have a minimum amount of signal-to-noise ratio. Vectors below a certain threshold are substituted by NaN. If you are not sure about which threshold value to use, try taking a look at the signal-to-noise ratio histogram with: plt.hist(sig2noise.flatten()).\n\n# clean the peaks that are below a quality threshold\ninvalid_mask = validation.sig2noise_val(\n    sig2noise,\n    threshold = 1.3,\n)\n\nAnother useful function is replace_outliers, which will find outlier vectors and substitute them with an average of neighboring vectors. The larger the kernel_size, the larger the considered neighborhood. This function uses an iterative image inpainting algorithm. The number of iterations can be chosen via max_iter.\n\n# replace those that are masked as bad vectors with local interpolation\nu, v = filters.replace_outliers(\n    u, v,\n    invalid_mask,\n    method='localmean',\n    max_iter=3,\n    kernel_size=3,\n)\n\nNext, we are going to convert pixels to millimeters.\n\n# scale the results from pix/dt to mm/sec\nx, y, u, v = scaling.uniform(x, y, u, v, scaling_factor = 96.52 ) # 96.52 pixels/millimeter",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>OpenPIV first tutorial</span>"
    ]
  },
  {
    "objectID": "tutorial.html#plot-and-save-the-results",
    "href": "tutorial.html#plot-and-save-the-results",
    "title": "2  OpenPIV first tutorial",
    "section": "2.3 Plot and save the results",
    "text": "2.3 Plot and save the results\nThe vector field can be plotted with display_vector_field. Vectors with signal-to-noise ratio below the threshold are displayed in red.\n\nimport pathlib\n\nfig, ax = plt.subplots(figsize=(9,4))\ntools.display_vector_field(\n    pathlib.Path('exp1_001.txt'),\n    ax=ax, scaling_factor=96.52,\n    scale=50, # scale defines here the arrow length\n    width=0.0035, # width is the thickness of the arrow\n    on_img=True, # overlay on the image\n    image_name= str('./images/exp1_001_b.bmp'),\n)\nplt.show()\n\n\n\n\n\n\n\n\nThe function save is used to save the vector field to a ASCII tabular file.\n\ntools.save('exp1_001.txt' , x, y, u, v, invalid_mask)",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>OpenPIV first tutorial</span>"
    ]
  },
  {
    "objectID": "tutorial.html#use-any-pair-of-images-that-you-can-access-via-url",
    "href": "tutorial.html#use-any-pair-of-images-that-you-can-access-via-url",
    "title": "2  OpenPIV first tutorial",
    "section": "3.1 Use any pair of images that you can access via URL",
    "text": "3.1 Use any pair of images that you can access via URL\nFor instance we can use images from PIV Challenge http://www.pivchallenge.org/\n\nframe_a = tools.imread('http://www.pivchallenge.org/pub/B/B001_1.tif')\nframe_b = tools.imread('http://www.pivchallenge.org/pub/B/B001_2.tif')\n#frame_a = tools.imread(\"./images/B005_1.tif\")\n#frame_b = tools.imread(\"./images/B005_2.tif\")\nfig,ax = plt.subplots(1,2,figsize=(10,8))\nax[0].imshow(frame_a,cmap=plt.cm.gray)\nax[1].imshow(frame_b,cmap=plt.cm.gray)\nplt.show()\n\n\n\n\n\n\n\n\n\nwinsize = 32 # pixels\nsearchsize = 64  # pixels, search in image B\noverlap = 16 # pixels\ndt = 1.0 # sec\nu, v, sig2noise = pyprocess.extended_search_area_piv( frame_a.astype(np.int32), frame_b.astype(np.int32), window_size=winsize, overlap=overlap, dt=dt, search_area_size=searchsize, sig2noise_method='peak2peak' )\n#x, y = pyprocess.get_coordinates( image_size=frame_a.shape, window_size=winsize, overlap=overlap )\nx, y = pyprocess.get_coordinates(\n    image_size=frame_a.shape,\n    search_area_size=searchsize,\n    overlap=overlap,\n)\n#u, v, mask = validation.sig2noise_val( u0, v0, sig2noise, threshold = 1.1 )\n#u, v = filters.replace_outliers( u, v, method='localmean', max_iter=10, kernel_size=2)\n#Post-processing\ninvalid_mask = validation.sig2noise_val(\n    sig2noise,\n    threshold = 1.1,\n)\n\nu, v = filters.replace_outliers(\n    u, v,\n    invalid_mask,\n    method='localmean',\n    max_iter=10,\n    kernel_size=2,\n)\n# x, y, u, v = scaling.uniform(x, y, u, v, scaling_factor = 96.52 )\n\nplt.figure(figsize=(9,4))\nplt.quiver(x,y,u,v,color='b')\nplt.quiver(x[invalid_mask],y[invalid_mask],u[invalid_mask],v[invalid_mask],color='r')\nplt.show()",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>OpenPIV first tutorial</span>"
    ]
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "3  Advanced PIV techniques",
    "section": "",
    "text": "3.1 How window deformation works\nThis page provides an in-depth overview of advanced Particle Image Velocimetry (PIV) techniques implemented in the OpenPIV Python package. It covers window deformation methods, multi-pass processing, vector validation, and image preprocessing techniques that go beyond basic PIV analysis.\nWindow deformation is an advanced technique that improves PIV accuracy by deforming interrogation windows based on previous displacement estimates. This is particularly useful for flows with high shear or rotation.\nWindow deformation iteratively deforms the interrogation windows to account for flow gradients within each window. This helps overcome the limitations of standard PIV which assumes uniform displacement within each interrogation region.\nOpenPIV supports two window deformation methods. 1. Symmetric Deformation: Both images are deformed by half the displacement in opposite directions. This is more accurate but computationally intensive. 2. Second Image Deformation: Only the second image is deformed. This is faster but potentially less accurate.",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "advanced.html#how-multi-pass-processing-works",
    "href": "advanced.html#how-multi-pass-processing-works",
    "title": "3  Advanced PIV techniques",
    "section": "3.2 How multi-pass processing works",
    "text": "3.2 How multi-pass processing works\nMulti-pass processing iteratively refines PIV analysis by using results from previous passes to guide subsequent analysis with smaller interrogation windows. This approach significantly improves spatial resolution and accuracy. 1. First pass uses large interrogation windows for robustness 2. Subsequent passes use smaller windows for better spatial resolution 3. Each pass uses results from the previous pass to deform windows",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "advanced.html#vector-validation-techniques",
    "href": "advanced.html#vector-validation-techniques",
    "title": "3  Advanced PIV techniques",
    "section": "3.3 Vector Validation Techniques",
    "text": "3.3 Vector Validation Techniques\nVector validation is crucial for identifying and removing spurious vectors from PIV results. OpenPIV implements several validation methods that can be used alone or in combination:\n\nGlobal Validation (global_val): Rejects vectors outside specified displacement ranges.\nGlobal Statistical Validation (global_std): Rejects vectors that deviate from the mean by more than a specified number of standard deviations.\nSignal-to-noise Validation (sig2noise_val): Rejects vectors with a low signal-to-noise ratio.\nLocal Median Validation (local_median_val): Rejects vectors that deviate significantly from their local neighborhood median.\nNormalized Local Median Validation (local_norm_median_val): A normalized version of local median validation that accounts for local flow variations.",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "advanced.html#vector-replacement",
    "href": "advanced.html#vector-replacement",
    "title": "3  Advanced PIV techniques",
    "section": "3.4 Vector Replacement",
    "text": "3.4 Vector Replacement\nAfter validation, identified outliers can be replaced using different methods:\n\nlocalmean: Replaces outliers with the local neighborhood mean\ndisk: Uses a disk-shaped kernel for replacement\ndistance: Weighted average based on distance",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "advanced.html#configuring-advanced-piv-analysis",
    "href": "advanced.html#configuring-advanced-piv-analysis",
    "title": "3  Advanced PIV techniques",
    "section": "3.5 Configuring Advanced PIV Analysis",
    "text": "3.5 Configuring Advanced PIV Analysis\nAdvanced PIV techniques are configured using the PIVSettings class, which provides a centralized way to control all aspects of the analysis.\n\n3.5.1 Key Settings\n\nwindowsizes: Tuple of interrogation window sizes for each pass (e.g., (64, 32, 16))\noverlap: Tuple of overlap values for each pass (e.g., (32, 16, 8))\nnum_iterations: Number of PIV passes\ncorrelation_method: Method for correlation (circular or linear)\ndeformation_method: Method for window deformation (symmetric or second image)\nvalidation_first_pass: Whether to validate the first pass\nreplace_vectors: Whether to replace outliers\nValidation thresholds: min_max_u_disp, min_max_v_disp, std_threshold, median_threshold, etc.\n\n\n\n3.5.2 Example Usage\nUsing advanced PIV techniques in OpenPIV involves setting up PIVSettings and calling the windef.piv() function:\n\n# Import necessary modules\nfrom openpiv import windef\nimport pathlib\n\nimage_path = pathlib.Path(r'./images/')\n\nfile_list = []\nfor path in sorted(image_path.rglob('*.tif')):\n    print(f'{path.name}')\n    file_list.append(path.name)\n\n# Create settings object\nsettings = windef.PIVSettings()\n\n# Data related settings\nsettings.filepath_images = image_path #'./images/' # Folder with the images to process\nsettings.save_path = './results/' # Folder for the outputs\n# Root name of the output Folder (if any) for Result Files\nsettings.save_folder_suffix = 'test'\n# Format and Image Sequence (see below for more options)\n#settings.frame_pattern_a = 'exp1_001_b.bmp'\n#settings.frame_pattern_b = 'exp1_001_c.bmp'\n# or if you have a sequence:\nsettings.frame_pattern_a = '*.tif'\n# settings.frame_pattern_b = '(1+2),(2+3)'\n# settings.frame_pattern_b = '(1+3),(2+4)'\nsettings.frame_pattern_b = '(1+2),(3+4)'\n\n# Format and Image Sequence\n#settings.frame_pattern_a = '*.bmp' # file_list[0]\n\n# settings.frame_pattern_b = file_list[1]\n#settings.frame_pattern_b = None\n\n# If you want only one pair\n#settings.frame_pattern_a = file_list[0]\n#settings.frame_pattern_b = file_list[1]\n\n\n# Region of interest: (xmin,xmax,ymin,ymax) or 'full' for full image\nsettings.roi = 'full'\n\n# Configure settings for advanced analysis\nsettings.windowsizes = (64, 32, 16) # it should be a power of 2\nsettings.overlap = (32, 16, 8) # This is 50% overlap. In general window size/2 is a good choice.\nsettings.num_iterations = 3 # select the number of PIV passes\nsettings.correlation_method = 'circular' # 'circular' or 'linear'\nsettings.normalized_correlation = False\nsettings.subpixel_method = 'gaussian' # 'gaussian','centroid','parabolic'\nsettings.deformation_method = 'symmetric'\nsettings.interpolation_order = 3 # order of the image interpolation for the window deformation\n\n# Signal to noise ratio options (only for the last pass)\n# It is possible to decide if the S/N should be computed (for the last pass) or not\n# If extract_sig2noise==False the values in the signal to noise ratio\n# output column are set to NaN\nsettings.extract_sig2noise = True  # 'True' or 'False' (only for the last pass)\nsettings.sig2noise_method = 'peak2peak' # 'peak2peak' or 'peak2mean'\n# select the width of the masked to masked out pixels next to the main peak\nsettings.sig2noise_mask = 2\n\n# Set vector validation parameters\nsettings.validation_first_pass = True # choose if you want to do validation of the first pass\n# The validation is done at each iteration based on three filters.\n# The first filter is based on the min/max ranges. Observe that these values are defined in\n# terms of minimum and maximum displacement in pixel/frames.\nsettings.min_max_u_disp = (-30, 30)\nsettings.min_max_v_disp = (-30, 30)\n# The second filter is based on the global STD threshold\nsettings.std_threshold = 7  # threshold of the std validation\n# The third filter is the median test (not normalized at the moment)\nsettings.median_threshold = 3  # threshold of the median validation\n# Validation based on the signal to noise ratio'\n# Note: only available when extract_sig2noise==True and only for the last\n# pass of the interrogation\n# Options: True or False\nsettings.sig2noise_threshold = 1.2 # minmum signal to noise ratio that is need for a valid vector\n\n# Outlier replacement or Smoothing options\n# Replacment options for vectors which are masked as invalid by the validation\nsettings.replace_vectors = True # True or False\nsettings.smoothn = True #Enables smoothing of the displacement field\nsettings.smoothn_p = 0.5 # This is a smoothing parameter\n# select a method to replace the outliers: 'localmean', 'disk', 'distance'\nsettings.filter_method = 'localmean'\n# maximum iterations performed to replace the outliers\nsettings.max_filter_iteration = 4\nsettings.filter_kernel_size = 2  # kernel size for the localmean method\n\nsettings.scaling_factor = 1  # scaling factor pixel/meter\nsettings.dt = 1  # time between to frames (in seconds)\n\n# Output options\n# Select if you want to save the plotted vector field: True or False\nsettings.save_plot = False\n# Choose wether you want to see the vectorfield or not :True or False\nsettings.show_plot = True\nsettings.scale_plot = 200  # select a value to scale the quiver plot of the vectorfield\n\n# Run PIV analysis with the given settings\nwindef.piv(settings)\n\nB005_1.tif\nB005_2.tif\nB005_3.tif\nB005_4.tif\nSaving to results/OpenPIV_results_16_test/field_A0000.txt\n\n\n\n\n\n\n\n\n\nImage Pair 1\nB005_1 B005_2\nSaving to results/OpenPIV_results_16_test/field_A0001.txt\n\n\n\n\n\n\n\n\n\nImage Pair 2\nB005_3 B005_4",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "advanced.html#conclusion",
    "href": "advanced.html#conclusion",
    "title": "3  Advanced PIV techniques",
    "section": "3.6 Conclusion",
    "text": "3.6 Conclusion\nAdvanced PIV techniques in OpenPIV provide powerful tools for improving accuracy and spatial resolution in PIV analysis. Window deformation and multi-pass processing address limitations of basic PIV analysis, while comprehensive validation methods ensure reliable vector fields. These techniques are particularly valuable for complex flows with high shear, rotation, or spatial gradients.",
    "crumbs": [
      "Numérique",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced PIV techniques</span>"
    ]
  },
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "4  Measurements",
    "section": "",
    "text": "4.1 Image recording\nYou will conduct experiments with the aim of determining the velocity field of a flow using PIV. The experiments are carried out in a glass aquarium measuring 80 x 35 x 40 cm³. An adaptable setup inside the aquarium allows for generating a recirculating flow. Its modest volume is well-suited for the space constraints of a practical laboratory exercise. However, you will notice that it has consequences on the established flow that you will analyze.\nThe flow is generated by 4 Aqua Medic Ecodrift 4.3 pumps. These are propeller pumps commonly used in aquariums. Each pump can produce an adjustable flow rate of up to approximately 4000 l/h, thus creating a controlled recirculating flow in the aquarium.\nThe images are acquired by the FlowSense 2M-165 camera, which connects directly to the computer via a USB 3 port, thus integrating the system directly within the computer without requiring an additional acquisition card. This camera offers a resolution of 1920 × 1200 pixels (2.3 megapixels), with a maximum acquisition frequency of 165 frames per second. It is therefore well-suited for time-resolved PIV for slow to moderate flows. Its pixel size is 5.9 μm, and the quantum efficiency of its sensor is greater than 70%, particularly adapted to the wavelengths of green light from lasers or LEDs. It uses a CMOS (Complementary Metal-Oxide-Semiconductor) sensor, which is widely used in modern PIV systems for its high acquisition rate.",
    "crumbs": [
      "Pratique",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Measurements</span>"
    ]
  },
  {
    "objectID": "practice.html#seeding-particles",
    "href": "practice.html#seeding-particles",
    "title": "4  Measurements",
    "section": "4.2 Seeding particles",
    "text": "4.2 Seeding particles\nThe seeding particles used are polyamide particles (PSP-50, ref. 9080A5011). These particles are produced by polymerization. They are round, but not perfectly spherical. The size distribution (diameter) of each particle is between 30 and 70 μm, with an average of 50 μm. Their density is 1.03 g/cm³, very close to that of water, which therefore limits their sedimentation. Their refractive index is 1.5.",
    "crumbs": [
      "Pratique",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Measurements</span>"
    ]
  },
  {
    "objectID": "practice.html#light-source",
    "href": "practice.html#light-source",
    "title": "4  Measurements",
    "section": "4.3 Light source",
    "text": "4.3 Light source\nIllumination is provided by the Fiber-Lite® Mi-LED light generator (Dolan-Jenner). This system delivers white light with a color temperature of 5000 K and represents a modern and economical alternative to conventional 150 W halogen sources.",
    "crumbs": [
      "Pratique",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Measurements</span>"
    ]
  },
  {
    "objectID": "practice.html#assignment",
    "href": "practice.html#assignment",
    "title": "4  Measurements",
    "section": "4.4 Assignment",
    "text": "4.4 Assignment\nDuring this practical session, you will get familiarized with a simple experimental setup designed to record particle images of a flow for which the velocity field is to be estimated.\nYou will be asked to study three particular flows: 1. a free flow (without any obstacle) 2. the flow that develops around/behind a cylinder 3. the flow that develops behind a step\neach of which with three flow regimes, i.e. for three different flow rates as given by the pumps.\nUne analyse approfondie des images obtenues sera attendue. Devront figurer parmi les points discutés, sans être exhaustif: la taille moyenne des particules images, leur densité, la gamme dynamique des niveaux de gris.",
    "crumbs": [
      "Pratique",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Measurements</span>"
    ]
  }
]